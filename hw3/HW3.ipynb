{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from ortools.linear_solver import pywraplp\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "NUM_FEATURES = 100\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "    \"\"\"Class to store VOC semantic segmentation dataset\"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, label_dir, file_list):\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        reader = open(file_list, \"r\")\n",
    "        self.files = []\n",
    "        for file in reader:\n",
    "            self.files.append(file.strip())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        # 0 stands for background, 1 for foreground\n",
    "        labels = np.load(os.path.join(self.label_dir, fname+\".npy\"))\n",
    "        labels[labels > 0.0] = 1.0\n",
    "        image = Image.open(os.path.join(self.image_dir, fname+\".jpg\"), \"r\")\n",
    "        sample = (TF.to_tensor(image), torch.LongTensor(labels))\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    \"\"\"Class defining AlexNet layers used for the convolutional network\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=2, padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FCNHead(nn.Sequential):\n",
    "    \"\"\"Class defining FCN (fully convolutional network) layers\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, channels):\n",
    "        inter_channels = in_channels // 4\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(inter_channels, channels, 1)\n",
    "        ]\n",
    "\n",
    "        super(FCNHead, self).__init__(*layers)\n",
    "\n",
    "\n",
    "class SimpleSegmentationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Class defining end-to-end semantic segmentation model.\n",
    "    It combines AlexNet and FCN layers with interpolation for deconvolution.\n",
    "    This model is pretrained using cross-entropy loss.\n",
    "    After pre-training, use the get_repr() function to construct 32x32x100 feature tensors for each image\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_feat, n_classes):\n",
    "        super(SimpleSegmentationModel, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.backbone = AlexNet()\n",
    "        self.classifier = FCNHead(256, n_feat)\n",
    "        self.linear = nn.Linear(n_feat, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = self.get_repr(x)\n",
    "        repr = repr.contiguous().view(-1, self.n_feat)\n",
    "        out = self.linear(repr)\n",
    "        return out\n",
    "\n",
    "    def get_repr(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        x = self.classifier(features)\n",
    "        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train_cnn(model, train_batches, num_epochs):\n",
    "    \"\"\"\n",
    "    This function runs a training loop for the FCN semantic segmentation model\n",
    "    \"\"\"\n",
    "    print(\"Training CNN...\")\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.Tensor([1, 4]).cuda())\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            output = model(images)\n",
    "            output = output.cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Training loss after epoch {}: {}\".format(epoch, total_loss/len(train_batches)))\n",
    "\n",
    "\n",
    "def test_cnn(model, test_batches):\n",
    "    \"\"\"\n",
    "        This function evaluates the FCN semantic segmentation model on the test set\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        class_gold = [0.0] * NUM_CLASSES\n",
    "        class_pred = [0.0] * NUM_CLASSES\n",
    "        class_correct = [0.0] * NUM_CLASSES\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            output = model(images).cuda()\n",
    "            labels = labels.cuda()\n",
    "            _, output = torch.max(output, axis=1)\n",
    "            visualize_grayscale_image(output.view(32, 32).cpu().numpy(), i)\n",
    "            output = output.squeeze().cpu().numpy()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze().cpu().numpy()\n",
    "            cur_class_pred = np.unique(output, return_counts=True)\n",
    "            for key, val in zip(cur_class_pred[0], cur_class_pred[1]):\n",
    "                class_pred[key] += val\n",
    "            cur_class_gold = np.unique(labels, return_counts=True)\n",
    "            for key, val in zip(cur_class_gold[0], cur_class_gold[1]):\n",
    "                class_gold[key] += val\n",
    "            cur_correct = (output == labels).tolist()\n",
    "            for j, val in enumerate(cur_correct):\n",
    "                if val:\n",
    "                    class_correct[labels[j]] += 1\n",
    "            correct += np.sum(cur_correct)\n",
    "            total += len(labels)\n",
    "        class_iou = [x/(y+z-x) for x, y, z in zip(class_correct, class_gold, class_pred)]\n",
    "        mean_iou = sum(class_iou) / len(class_correct)\n",
    "        print(\"CNN Mean IOU: {}\".format(mean_iou))\n",
    "        print(\"CNN Pixel Accuracy: {}\".format(correct / total))\n",
    "\n",
    "\n",
    "\n",
    "def visualize_grayscale_image(image, file=None, save=False):\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    # Uncomment this to visualize image\n",
    "    # plt.show()\n",
    "    # Uncomment this to save image\n",
    "    # plt.savefig(str(file)+\".png\")\n",
    "    if save==True:\n",
    "        plt.savefig(strftime(\"%Y-%m-%d_%H:%M\", gmtime())+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN...\n",
      "Training loss after epoch 0: 0.6340523127317429\n",
      "Training loss after epoch 1: 0.631809357970953\n",
      "Training loss after epoch 2: 0.6295247563123703\n",
      "Training loss after epoch 3: 0.6290496337711811\n",
      "Training loss after epoch 4: 0.6285039240717888\n",
      "CNN Mean IOU: 0.43130065201457946\n",
      "CNN Pixel Accuracy: 0.7223984375\n",
      "CNN Mean IOU: 0.43180180157332526\n",
      "CNN Pixel Accuracy: 0.7198036154588336\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Uncomment following lines after providing appropriate paths\n",
    "train_dataset = VOCDataset('data/DownsampledImages', 'data/DownsampledLabels', 'data/train.txt')\n",
    "test_dataset = VOCDataset('data/DownsampledImages', 'data/DownsampledLabels', 'data/test.txt')\n",
    "\n",
    "train_batches = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_batches = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "cnn = SimpleSegmentationModel(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "train_cnn(cnn, train_batches, 5)\n",
    "test_cnn(cnn, train_batches)\n",
    "test_cnn(cnn, test_batches)\n",
    "\n",
    "# TODO: Instantiate a linear SVM and call train/ test functions\n",
    "# TODO: Instantiate a structured SVM and call train/ test functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSVM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feat, n_classes):\n",
    "        super(LinearSVM, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.n_classes = n_classes\n",
    "        self.w = nn.Parameter(torch.zeros(n_classes, n_feat), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.zeros(n_classes).unsqueeze(0), requires_grad=True)\n",
    "        # TODO: Define weights for linear SVM\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Define forward function for linear SVM\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        return x.matmul(self.w.t()) + self.b\n",
    "    \n",
    "class MyHingeLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyHingeLoss, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        n = target.shape[0]\n",
    "        target_new = torch.zeros((n,2),dtype=torch.long).cuda()\n",
    "        for i in range(n):\n",
    "            target_new[i,target[i]] = 1\n",
    "        all_ones = torch.ones_like(target_new)\n",
    "        labels = 2 * target_new - all_ones\n",
    "        losses = all_ones - torch.mul(output, labels)\n",
    "\n",
    "        return torch.norm(self.relu(losses))\n",
    "    \n",
    "#     def forward(self, output, target):\n",
    "#         all_ones = torch.ones_like(target)\n",
    "#         labels = target\n",
    "#         losses = all_ones - torch.mul(output, labels)\n",
    "\n",
    "#         return torch.norm(self.relu(losses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_2d(target):\n",
    "    n = target.shape[0]\n",
    "    target_new = torch.zeros((n,2),dtype=torch.long).cuda()\n",
    "    for i in range(n):\n",
    "        target_new[i,target[i]] = 1\n",
    "    return target_new\n",
    "\n",
    "def train_linear_svm(cnn_model, svm_model, train_batches, test_batches, num_epochs):\n",
    "    # TODO: Write a training loop for the linear SVM\n",
    "    # Keep in mind that the CNN model is needed to compute features, but it should not be finetuned\n",
    "    \n",
    "    print(\"Training Linear SVM...\")\n",
    "    criterion = MyHingeLoss()\n",
    "    # criterion = nn.MultiLabelMarginLoss()\n",
    "    optimizer = optim.Adam(svm_model.parameters(), lr=0.0001)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            output = svm_model(cnn_model.get_repr(images)).squeeze()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            # labels = labels.contiguous().view(-1, 1).repeat((1,2))\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Training loss after epoch {}: {}\".format(epoch, total_loss/len(train_batches)))\n",
    "        test_linear_svm(cnn_model, svm_model, test_batches)\n",
    "    return\n",
    "\n",
    "\n",
    "def test_linear_svm(cnn_model, svm_model, test_batches):\n",
    "    criterion = MyHingeLoss()\n",
    "    # criterion = nn.MultiLabelMarginLoss()\n",
    "    # TODO: Write a testing function for the linear SVM\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        class_gold = [0.0] * NUM_CLASSES\n",
    "        class_pred = [0.0] * NUM_CLASSES\n",
    "        class_correct = [0.0] * NUM_CLASSES\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            output = svm_model(cnn_model.get_repr(images))\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, output = torch.max(output, axis=1)\n",
    "            visualize_grayscale_image(output.view(32, 32).cpu().numpy(), i)\n",
    "            output = output.squeeze().cpu().numpy().astype(int)\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze().cpu().numpy()\n",
    "            cur_class_pred = np.unique(output, return_counts=True)\n",
    "            for key, val in zip(cur_class_pred[0], cur_class_pred[1]):\n",
    "                class_pred[key] += val\n",
    "            cur_class_gold = np.unique(labels, return_counts=True)\n",
    "            for key, val in zip(cur_class_gold[0], cur_class_gold[1]):\n",
    "                class_gold[key] += val\n",
    "            cur_correct = (output == labels).tolist()\n",
    "            for j, val in enumerate(cur_correct):\n",
    "                if val:\n",
    "                    class_correct[labels[j]] += 1\n",
    "            correct += np.sum(cur_correct)\n",
    "            total += len(labels)\n",
    "        print(\"Testing loss after epoch: {}\".format(total_loss/len(test_batches)))\n",
    "        class_iou = [x/(y+z-x) for x, y, z in zip(class_correct, class_gold, class_pred)]\n",
    "        mean_iou = sum(class_iou) / len(class_correct)\n",
    "        print(\"LinearSVM Mean IOU: {}\".format(mean_iou))\n",
    "        print(\"LinearSVM Pixel Accuracy: {}\".format(correct / total))\n",
    "        print()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM...\n",
      "Training loss after epoch 0: 38.42778907775879\n",
      "Testing loss after epoch: 35.25559211881451\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n",
      "Training loss after epoch 1: 34.44132444190979\n",
      "Testing loss after epoch: 34.282492273667664\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n",
      "Training loss after epoch 2: 33.880603281497955\n",
      "Testing loss after epoch: 33.89866800332764\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n",
      "Testing loss after epoch: 33.7090067076683\n",
      "LinearSVM Mean IOU: 0.39865185546875\n",
      "LinearSVM Pixel Accuracy: 0.7973037109375\n",
      "\n",
      "Testing loss after epoch: 33.89866800332764\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = LinearSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "# svm = LinearSVM(NUM_FEATURES, 1).cuda()\n",
    "\n",
    "train_linear_svm(cnn, svm, train_batches, test_batches, 3)\n",
    "test_linear_svm(cnn, svm, train_batches)\n",
    "test_linear_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_model(var_pot, edge_pot, target):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    assert var_pot.shape[0]==target.shape[0]\n",
    "    data = {}\n",
    "    n = 32\n",
    "    y_coef = []\n",
    "    x_coef = []\n",
    "    for i in range(edge_pot.shape[0]):\n",
    "        y_coef.append(int(var_pot.shape[0] * (edge_pot[i][0] - edge_pot[i][1])))\n",
    "        \n",
    "    for i in range(var_pot.shape[0]):\n",
    "        x_coef.append(int(var_pot.shape[0] * (var_pot[i][0] - var_pot[i][1]) + (2 * target[i] - 1)))\n",
    "    data['obj_coeffs'] = x_coef + y_coef\n",
    "    data['num_vars'] = var_pot.shape[0] + edge_pot.shape[0]\n",
    "    \n",
    "    \n",
    "    data['constraint_coeffs'] = []\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(0,n-1):\n",
    "        for j in range(0,n-1):\n",
    "            cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons1[i*n+j] = -1\n",
    "            cons1[idx+var_pot.shape[0]] = 1\n",
    "            cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons2[i*n+j+1] = -1\n",
    "            cons2[idx+var_pot.shape[0]] = 1\n",
    "            data['constraint_coeffs'].append(cons1)\n",
    "            data['constraint_coeffs'].append(cons2)\n",
    "            idx = idx + 1\n",
    "            \n",
    "            cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons1[i*n+j] = -1\n",
    "            cons1[idx+var_pot.shape[0]] = 1\n",
    "            cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons2[i*n+j+n] = -1\n",
    "            cons2[idx+var_pot.shape[0]] = 1\n",
    "            data['constraint_coeffs'].append(cons1)\n",
    "            data['constraint_coeffs'].append(cons2)\n",
    "            idx = idx + 1\n",
    "\n",
    "        cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons1[i*n+n-1] = -1\n",
    "        cons1[idx+var_pot.shape[0]] = 1\n",
    "        cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons2[i*n+n+n-1] = -1\n",
    "        cons2[idx+var_pot.shape[0]] = 1\n",
    "        data['constraint_coeffs'].append(cons1)\n",
    "        data['constraint_coeffs'].append(cons2)\n",
    "        idx = idx + 1\n",
    "\n",
    "    for j in range(0,n-1):\n",
    "        cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons1[(n-1)*n+j] = -1\n",
    "        cons1[idx+var_pot.shape[0]] = 1\n",
    "        cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons2[(n-1)*n+j+1] = -1\n",
    "        cons2[idx+var_pot.shape[0]] = 1\n",
    "        data['constraint_coeffs'].append(cons1)\n",
    "        data['constraint_coeffs'].append(cons2)\n",
    "        idx = idx + 1\n",
    "\n",
    "\n",
    "    assert idx == 2*(n-1)*n\n",
    "    \n",
    "    data['bounds'] = [0] * 2 * edge_pot.shape[0]\n",
    "    \n",
    "    assert len(data['bounds'])==len(data['constraint_coeffs'])\n",
    "    data['num_constraints'] = len(data['bounds'])\n",
    "    return data\n",
    "\n",
    "\n",
    "def MAP_infer(data):\n",
    "    \n",
    "    solver = pywraplp.Solver('ILP', pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "    infinity = solver.infinity()\n",
    "    x = {}\n",
    "    for j in range(data['num_vars']):\n",
    "        x[j] = solver.IntVar(0, 1, 'x[%i]' % j)\n",
    "    # print('Number of variables =', solver.NumVariables())\n",
    "\n",
    "    for i in range(data['num_constraints']):\n",
    "        constraint = solver.RowConstraint(0, data['bounds'][i], '')\n",
    "    for j in range(data['num_vars']):\n",
    "        constraint.SetCoefficient(x[j], data['constraint_coeffs'][i][j])\n",
    "    # print('Number of constraints =', solver.NumConstraints())\n",
    "    \n",
    "    # In Python, you can also set the constraints as follows.\n",
    "    # for i in range(data['num_constraints']):\n",
    "    #  constraint_expr = \\\n",
    "    # [data['constraint_coeffs'][i][j] * x[j] for j in range(data['num_vars'])]\n",
    "    #  solver.Add(sum(constraint_expr) <= data['bounds'][i])\n",
    "\n",
    "    objective = solver.Objective()\n",
    "    for j in range(data['num_vars']):\n",
    "        objective.SetCoefficient(x[j], data['obj_coeffs'][j])\n",
    "    objective.SetMaximization()\n",
    "    # In Python, you can also set the objective as follows.\n",
    "    # obj_expr = [data['obj_coeffs'][j] * x[j] for j in range(data['num_vars'])]\n",
    "    # solver.Maximize(solver.Sum(obj_expr))\n",
    "\n",
    "    status = solver.Solve()\n",
    "\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        result = []\n",
    "        # print('Objective value =', solver.Objective().Value())\n",
    "        for j in range(data['num_vars']):\n",
    "            result.append(x[j].solution_value())\n",
    "            # print(x[j].name(), ' = ', x[j].solution_value())\n",
    "        #print()\n",
    "        #print('Problem solved in %f milliseconds' % solver.wall_time())\n",
    "        #print('Problem solved in %d iterations' % solver.iterations())\n",
    "        #print('Problem solved in %d branch-and-bound nodes' % solver.nodes())\n",
    "        return result\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.')\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def make_y(x):\n",
    "        n = x.size(1)\n",
    "        dim = x.size(-1)\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        y = torch.zeros((2*(n-1)*n ,2*dim))\n",
    "        y_dict = dict()\n",
    "        \n",
    "        idx = 0\n",
    "        for i in range(0,n-1):\n",
    "            for j in range(0,n-1):\n",
    "                y_dict[(idx,(i*n+j,i*n+j+1))] = torch.cat([x[i*n+j],x[i*n+j+1]])\n",
    "                idx = idx + 1\n",
    "                y_dict[(idx,(i*n+j,i*n+j+n))] = torch.cat([x[i*n+j],x[i*n+j+n]])\n",
    "                idx = idx + 1\n",
    "        \n",
    "            y_dict[(idx,(i*n+n-1,i*n+n+n-1))] = torch.cat([x[i*n+n-1],x[i*n+n+n-1]])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        for j in range(0,n-1):\n",
    "            y_dict[(idx,((n-1)*n+j,(n-1)*n+j+1))] = torch.cat([x[(n-1)*n+j],x[(n-1)*n+j+1]])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        assert idx == 2*(n-1)*n\n",
    "        for key in y_dict.keys():\n",
    "            y[key[0],:] = y_dict[key]\n",
    "        \n",
    "        return y, y_dict\n",
    "    \n",
    "    \n",
    "def make_y_label(x):\n",
    "        n = x.size(1)\n",
    "        dim = x.size(-1)\n",
    "        assert dim==2\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        x = x[:,0]\n",
    "        y = torch.zeros((2*(n-1)*n ,dim))\n",
    "        y_dict = dict()\n",
    "        \n",
    "        idx = 0\n",
    "        for i in range(0,n-1):\n",
    "            for j in range(0,n-1):\n",
    "                y_dict[(idx,(i*n+j,i*n+j+1))] = int(x[i*n+j]==x[i*n+j+1])\n",
    "                idx = idx + 1\n",
    "                y_dict[(idx,(i*n+j,i*n+j+n))] = int(x[i*n+j]==x[i*n+j+n])\n",
    "                idx = idx + 1\n",
    "        \n",
    "            y_dict[(idx,(i*n+n-1,i*n+n+n-1))] = int(x[i*n+n-1]==x[i*n+n+n-1])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        for j in range(0,n-1):\n",
    "            y_dict[(idx,((n-1)*n+j,(n-1)*n+j+1))] = int(x[(n-1)*n+j]==x[(n-1)*n+j+1])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        assert idx == 2*(n-1)*n\n",
    "        for key in y_dict.keys():\n",
    "            y[key[0],y_dict[key]] = 1\n",
    "        \n",
    "        return y, y_dict\n",
    "\n",
    "class StructSVM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feat, n_classes):\n",
    "        super(StructSVM, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.n_classes = n_classes\n",
    "        self.w_var = nn.Parameter(torch.ones(n_classes, n_feat), requires_grad=True)\n",
    "        self.w_edge = nn.Parameter(torch.ones(n_classes, 2*n_feat), requires_grad=True)\n",
    "        # TODO: Define weights for structured SVM\n",
    "       \n",
    "\n",
    "    def forward(self, x, target):\n",
    "        # TODO: Define forward function for structured SVM\n",
    "        y, _ = make_y(x)\n",
    "        y = y.cuda()\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        var_pot = x.matmul(self.w_var.t())\n",
    "        edge_pot = y.matmul(self.w_edge.t())\n",
    "        data = create_data_model(torch.clone(var_pot).cpu().detach().numpy().squeeze(), \n",
    "                                 torch.clone(edge_pot).cpu().detach().numpy().squeeze(), \n",
    "                                 torch.clone(target).cpu().detach().numpy().squeeze())\n",
    "        result = MAP_infer(data)\n",
    "        x_out = torch.zeros((var_pot.size(0),2))\n",
    "        y_out = torch.zeros((edge_pot.size(0),2))\n",
    "        for i in range(var_pot.size(0)):\n",
    "            x_out[i,0] = result[i]\n",
    "            x_out[i,1] = 1 - result[i]\n",
    "        for i in range(edge_pot.size(0)):\n",
    "            y_out[i, 0] = result[i + var_pot.size(0)]\n",
    "            y_out[i, 1] = 1 - result[i + var_pot.size(0)]\n",
    "        return x_out.cuda(), y_out.cuda(), var_pot.cuda().squeeze(), edge_pot.cuda().squeeze()\n",
    "    \n",
    "\n",
    "\n",
    "class MyStructedHingeLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyStructedHingeLoss, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "    \n",
    "    def S_func(self, x, y, var_pot, edge_pot):\n",
    "        \n",
    "        sum_x_out = torch.sum(var_pot*x)\n",
    "        sum_y_out = torch.sum(edge_pot*y)\n",
    "        \n",
    "        return sum_x_out + sum_y_out\n",
    "    \n",
    "    def x_loss(self, x, target_x):\n",
    "        assert x.shape[0]==target_x.shape[0]\n",
    "        x0 = x[:,0]\n",
    "        xt0 = target_x[:,0]\n",
    "        return 1 - torch.sum(x0==xt0)/x.shape[0]\n",
    "    \n",
    "    def forward(self, x_out, y_out, var_pot, edge_pot, target):\n",
    "        S_output = self.S_func(x_out, y_out, var_pot, edge_pot)\n",
    "        target_x = torch.zeros((target.size(0),2))\n",
    "        for i in range(target.size(0)):\n",
    "            target_x[i, target[i]] = 1\n",
    "        target_y, _ = make_y_label(target_x.reshape(1,32,32,-1))\n",
    "        target_x = target_x.cuda()\n",
    "        target_y = target_y.cuda()\n",
    "        S_target = self.S_func(target_x, target_y, var_pot, edge_pot)\n",
    "        loss_x = self.x_loss(x_out, target_x)\n",
    "        losses = S_output + loss_x - S_target\n",
    "        return torch.sum(self.relu(losses))\n",
    "\n",
    "def train_struct_svm(cnn_model, svm_model, train_batches, test_batches, num_epochs):\n",
    "    # TODO: Write a training loop for the structured SVM\n",
    "    # Keep in mind that the CNN model is needed to compute features, but it should not be finetuned\n",
    "    print(\"Training Struct SVM...\")\n",
    "    criterion = MyStructedHingeLoss()\n",
    "    optimizer = optim.Adam(svm_model.parameters(), lr=0.0001) \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            x_out, y_out, var_pot, edge_pot = svm_model(cnn_model.get_repr(images), labels)\n",
    "            loss = criterion(x_out, y_out, var_pot, edge_pot, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Training loss after epoch {}: {}\".format(epoch, total_loss/len(train_batches)))\n",
    "        test_struct_svm(cnn_model, svm_model, test_batches)\n",
    "    return\n",
    "\n",
    "\n",
    "def test_struct_svm(cnn_model, svm_model, test_batches):\n",
    "    # TODO: Write a testing function for the structured SVM\n",
    "    criterion = MyStructedHingeLoss()\n",
    "    with torch.no_grad():\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        class_gold = [0.0] * NUM_CLASSES\n",
    "        class_pred = [0.0] * NUM_CLASSES\n",
    "        class_correct = [0.0] * NUM_CLASSES\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            x_out, y_out, var_pot, edge_pot = svm_model(cnn_model.get_repr(images), labels)\n",
    "            loss = criterion(x_out, y_out, var_pot, edge_pot, labels)\n",
    "            total_loss += loss.item()        \n",
    "            _, output = torch.max(x_out, axis=1)\n",
    "            visualize_grayscale_image(output.view(32, 32).cpu().numpy(), i)\n",
    "            output = output.squeeze().cpu().numpy().astype(int)\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze().cpu().numpy()\n",
    "            cur_class_pred = np.unique(output, return_counts=True)\n",
    "            for key, val in zip(cur_class_pred[0], cur_class_pred[1]):\n",
    "                class_pred[key] += val\n",
    "            cur_class_gold = np.unique(labels, return_counts=True)\n",
    "            for key, val in zip(cur_class_gold[0], cur_class_gold[1]):\n",
    "                class_gold[key] += val\n",
    "            cur_correct = (output == labels).tolist()\n",
    "            for j, val in enumerate(cur_correct):\n",
    "                if val:\n",
    "                    class_correct[labels[j]] += 1\n",
    "            correct += np.sum(cur_correct)\n",
    "            total += len(labels)\n",
    "        \n",
    "        print(\"Testing loss after epoch: {}\".format(total_loss/len(test_batches)))\n",
    "        class_iou = [x/(y+z-x) for x, y, z in zip(class_correct, class_gold, class_pred)]\n",
    "        mean_iou = sum(class_iou) / len(class_correct)\n",
    "        print(\"StructSVM Mean IOU: {}\".format(mean_iou))\n",
    "        print(\"StructSVM Pixel Accuracy: {}\".format(correct / total))\n",
    "        print()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Struct SVM...\n",
      "Training loss after epoch 0: 1.59883642578125\n",
      "Testing loss after epoch: 1.195144993567753\n",
      "StructSVM Mean IOU: 0.25020651965686713\n",
      "StructSVM Pixel Accuracy: 0.4993199238850772\n",
      "\n",
      "Training loss after epoch 1: 1.95348828125\n",
      "Testing loss after epoch: 2.7242366731882504\n",
      "StructSVM Mean IOU: 0.3996097514378091\n",
      "StructSVM Pixel Accuracy: 0.6681865083619211\n",
      "\n",
      "Training loss after epoch 2: 1.6813544921875\n",
      "Testing loss after epoch: 8.386810878537736\n",
      "StructSVM Mean IOU: 0.30548136173024787\n",
      "StructSVM Pixel Accuracy: 0.6107619532590052\n",
      "\n",
      "Training loss after epoch 3: 1.6673408203125\n",
      "Testing loss after epoch: 1.3474016402229845\n",
      "StructSVM Mean IOU: 0.19309700338238556\n",
      "StructSVM Pixel Accuracy: 0.3333478505574614\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41ec2293a96e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStructSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_struct_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_struct_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_struct_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-662581c0237c>\u001b[0m in \u001b[0;36mtrain_struct_svm\u001b[0;34m(cnn_model, svm_model, train_batches, test_batches, num_epochs)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mx_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_pot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_pot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_pot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_pot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-662581c0237c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# TODO: Define forward function for structured SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-662581c0237c>\u001b[0m in \u001b[0;36mmake_y\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7fa5f99533a0> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2191\u001b[0m                            else suppress())\n\u001b[1;32m   2192\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m                     bbox_inches = self.figure.get_tightbbox(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2745\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2747\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             im, l, b, trans = self.make_image(\n\u001b[0m\u001b[1;32m    644\u001b[0m                 renderer, renderer.get_image_magnification())\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    926\u001b[0m         clip = ((self.get_clip_box() or self.axes.bbox) if self.get_clip_on()\n\u001b[1;32m    927\u001b[0m                 else self.figure.bbox)\n\u001b[0;32m--> 928\u001b[0;31m         return self._make_image(self._A, bbox, transformed_bbox, clip,\n\u001b[0m\u001b[1;32m    929\u001b[0m                                 magnification, unsampled=unsampled)\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    545\u001b[0m                                        \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_vmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                                        ):\n\u001b[0;32m--> 547\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_masked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, value, clip)\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;31m# ma division is very slow; we can take a shortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mresdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0mresdat\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0mresdat\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = StructSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "\n",
    "train_struct_svm(cnn, svm, train_batches, test_batches, 5)\n",
    "test_struct_svm(cnn, svm, train_batches)\n",
    "test_struct_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Struct SVM...\n",
      "Training loss after epoch 0: 1.8219443359375\n",
      "Testing loss after epoch: 0.7812089609240995\n",
      "StructSVM Mean IOU: 0.2886221194510217\n",
      "StructSVM Pixel Accuracy: 0.5771434123070326\n",
      "\n",
      "Training loss after epoch 1: 1.7334931640625\n",
      "Testing loss after epoch: 1.6731078473413379\n",
      "StructSVM Mean IOU: 0.2808926425588986\n",
      "StructSVM Pixel Accuracy: 0.5616155660377359\n",
      "\n",
      "Training loss after epoch 2: 1.5113525390625\n",
      "Testing loss after epoch: 1.5924660631968268\n",
      "StructSVM Mean IOU: 0.3811725868805567\n",
      "StructSVM Pixel Accuracy: 0.7623385237993139\n",
      "\n",
      "Training loss after epoch 3: 1.59384716796875\n",
      "Testing loss after epoch: 1.5415809592088336\n",
      "StructSVM Mean IOU: 0.32008887891295024\n",
      "StructSVM Pixel Accuracy: 0.6401777578259005\n",
      "\n",
      "Training loss after epoch 4: 1.8127265625\n",
      "Testing loss after epoch: 1.8644923215051459\n",
      "StructSVM Mean IOU: 0.39419012348011595\n",
      "StructSVM Pixel Accuracy: 0.7880557863421955\n",
      "\n",
      "Testing loss after epoch: 1.8161240234375\n",
      "StructSVM Mean IOU: 0.39179452303475293\n",
      "StructSVM Pixel Accuracy: 0.7833056640625\n",
      "\n",
      "Testing loss after epoch: 1.8644923215051459\n",
      "StructSVM Mean IOU: 0.39419012348011595\n",
      "StructSVM Pixel Accuracy: 0.7880557863421955\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = StructSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "\n",
    "train_struct_svm(cnn, svm, train_batches, test_batches, 5)\n",
    "test_struct_svm(cnn, svm, train_batches)\n",
    "test_struct_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Struct SVM...\n",
      "Training loss after epoch 0: 1.80068701171875\n",
      "Testing loss after epoch: 1.2287844728237565\n",
      "StructSVM Mean IOU: 0.37548324870972616\n",
      "StructSVM Pixel Accuracy: 0.7508593079974271\n",
      "\n",
      "Training loss after epoch 1: 1.55786865234375\n",
      "Testing loss after epoch: 1.2760581381325042\n",
      "StructSVM Mean IOU: 0.22243471134694276\n",
      "StructSVM Pixel Accuracy: 0.44263407214837047\n",
      "\n",
      "Training loss after epoch 2: 1.7956650390625\n",
      "Testing loss after epoch: 1.3600324627465694\n",
      "StructSVM Mean IOU: 0.36345467146804006\n",
      "StructSVM Pixel Accuracy: 0.7265976763507719\n",
      "\n",
      "Training loss after epoch 3: 1.8317763671875\n",
      "Testing loss after epoch: 1.7321019377144082\n",
      "StructSVM Mean IOU: 0.3088849972244766\n",
      "StructSVM Pixel Accuracy: 0.6175643894725558\n",
      "\n",
      "Training loss after epoch 4: 1.79480078125\n",
      "Testing loss after epoch: 0.8316577106560892\n",
      "StructSVM Mean IOU: 0.33391710300817223\n",
      "StructSVM Pixel Accuracy: 0.6678297196612349\n",
      "\n",
      "Testing loss after epoch: 0.8120087890625\n",
      "StructSVM Mean IOU: 0.3275340674594989\n",
      "StructSVM Pixel Accuracy: 0.6550556640625\n",
      "\n",
      "Testing loss after epoch: 0.8316577106560892\n",
      "StructSVM Mean IOU: 0.33391710300817223\n",
      "StructSVM Pixel Accuracy: 0.6678297196612349\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = StructSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "\n",
    "train_struct_svm(cnn, svm, train_batches, test_batches, 5)\n",
    "test_struct_svm(cnn, svm, train_batches)\n",
    "test_struct_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
