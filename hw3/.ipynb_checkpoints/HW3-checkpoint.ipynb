{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from ortools.linear_solver import pywraplp\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "NUM_FEATURES = 100\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "    \"\"\"Class to store VOC semantic segmentation dataset\"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, label_dir, file_list):\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        reader = open(file_list, \"r\")\n",
    "        self.files = []\n",
    "        for file in reader:\n",
    "            self.files.append(file.strip())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        # 0 stands for background, 1 for foreground\n",
    "        labels = np.load(os.path.join(self.label_dir, fname+\".npy\"))\n",
    "        labels[labels > 0.0] = 1.0\n",
    "        image = Image.open(os.path.join(self.image_dir, fname+\".jpg\"), \"r\")\n",
    "        sample = (TF.to_tensor(image), torch.LongTensor(labels))\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    \"\"\"Class defining AlexNet layers used for the convolutional network\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=2, padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FCNHead(nn.Sequential):\n",
    "    \"\"\"Class defining FCN (fully convolutional network) layers\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, channels):\n",
    "        inter_channels = in_channels // 4\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(inter_channels, channels, 1)\n",
    "        ]\n",
    "\n",
    "        super(FCNHead, self).__init__(*layers)\n",
    "\n",
    "\n",
    "class SimpleSegmentationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Class defining end-to-end semantic segmentation model.\n",
    "    It combines AlexNet and FCN layers with interpolation for deconvolution.\n",
    "    This model is pretrained using cross-entropy loss.\n",
    "    After pre-training, use the get_repr() function to construct 32x32x100 feature tensors for each image\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_feat, n_classes):\n",
    "        super(SimpleSegmentationModel, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.backbone = AlexNet()\n",
    "        self.classifier = FCNHead(256, n_feat)\n",
    "        self.linear = nn.Linear(n_feat, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = self.get_repr(x)\n",
    "        repr = repr.contiguous().view(-1, self.n_feat)\n",
    "        out = self.linear(repr)\n",
    "        return out\n",
    "\n",
    "    def get_repr(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        x = self.classifier(features)\n",
    "        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train_cnn(model, train_batches, num_epochs):\n",
    "    \"\"\"\n",
    "    This function runs a training loop for the FCN semantic segmentation model\n",
    "    \"\"\"\n",
    "    print(\"Training CNN...\")\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.Tensor([1, 4]).cuda())\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            output = model(images)\n",
    "            output = output.cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Training loss after epoch {}: {}\".format(epoch, total_loss/len(train_batches)))\n",
    "\n",
    "\n",
    "def test_cnn(model, test_batches):\n",
    "    \"\"\"\n",
    "        This function evaluates the FCN semantic segmentation model on the test set\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        class_gold = [0.0] * NUM_CLASSES\n",
    "        class_pred = [0.0] * NUM_CLASSES\n",
    "        class_correct = [0.0] * NUM_CLASSES\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            output = model(images).cuda()\n",
    "            labels = labels.cuda()\n",
    "            _, output = torch.max(output, axis=1)\n",
    "            visualize_grayscale_image(output.view(32, 32).cpu().numpy(), i)\n",
    "            output = output.squeeze().cpu().numpy()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze().cpu().numpy()\n",
    "            cur_class_pred = np.unique(output, return_counts=True)\n",
    "            for key, val in zip(cur_class_pred[0], cur_class_pred[1]):\n",
    "                class_pred[key] += val\n",
    "            cur_class_gold = np.unique(labels, return_counts=True)\n",
    "            for key, val in zip(cur_class_gold[0], cur_class_gold[1]):\n",
    "                class_gold[key] += val\n",
    "            cur_correct = (output == labels).tolist()\n",
    "            for j, val in enumerate(cur_correct):\n",
    "                if val:\n",
    "                    class_correct[labels[j]] += 1\n",
    "            correct += np.sum(cur_correct)\n",
    "            total += len(labels)\n",
    "        class_iou = [x/(y+z-x) for x, y, z in zip(class_correct, class_gold, class_pred)]\n",
    "        mean_iou = sum(class_iou) / len(class_correct)\n",
    "        print(\"CNN Mean IOU: {}\".format(mean_iou))\n",
    "        print(\"CNN Pixel Accuracy: {}\".format(correct / total))\n",
    "\n",
    "\n",
    "\n",
    "def visualize_grayscale_image(image, file=None, save=False):\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    # Uncomment this to visualize image\n",
    "    # plt.show()\n",
    "    # Uncomment this to save image\n",
    "    # plt.savefig(str(file)+\".png\")\n",
    "    if save==True:\n",
    "        plt.savefig(strftime(\"%Y-%m-%d_%H:%M\", gmtime())+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN...\n",
      "Training loss after epoch 0: 0.6340523127317429\n",
      "Training loss after epoch 1: 0.631809357970953\n",
      "Training loss after epoch 2: 0.6295247563123703\n",
      "Training loss after epoch 3: 0.6290496337711811\n",
      "Training loss after epoch 4: 0.6285039240717888\n",
      "CNN Mean IOU: 0.43130065201457946\n",
      "CNN Pixel Accuracy: 0.7223984375\n",
      "CNN Mean IOU: 0.43180180157332526\n",
      "CNN Pixel Accuracy: 0.7198036154588336\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Uncomment following lines after providing appropriate paths\n",
    "train_dataset = VOCDataset('data/DownsampledImages', 'data/DownsampledLabels', 'data/train.txt')\n",
    "test_dataset = VOCDataset('data/DownsampledImages', 'data/DownsampledLabels', 'data/test.txt')\n",
    "\n",
    "train_batches = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_batches = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "cnn = SimpleSegmentationModel(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "train_cnn(cnn, train_batches, 5)\n",
    "test_cnn(cnn, train_batches)\n",
    "test_cnn(cnn, test_batches)\n",
    "\n",
    "# TODO: Instantiate a linear SVM and call train/ test functions\n",
    "# TODO: Instantiate a structured SVM and call train/ test functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSVM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feat, n_classes):\n",
    "        super(LinearSVM, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.n_classes = n_classes\n",
    "        self.w = nn.Parameter(torch.zeros(n_classes, n_feat), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.zeros(n_classes).unsqueeze(0), requires_grad=True)\n",
    "        # TODO: Define weights for linear SVM\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Define forward function for linear SVM\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        return x.matmul(self.w.t()) + self.b\n",
    "    \n",
    "class MyHingeLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyHingeLoss, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        n = target.shape[0]\n",
    "        target_new = torch.zeros((n,2),dtype=torch.long).cuda()\n",
    "        for i in range(n):\n",
    "            target_new[i,target[i]] = 1\n",
    "        all_ones = torch.ones_like(target_new)\n",
    "        labels = 2 * target_new - all_ones\n",
    "        losses = all_ones - torch.mul(output, labels)\n",
    "\n",
    "        return torch.norm(self.relu(losses))\n",
    "    \n",
    "#     def forward(self, output, target):\n",
    "#         all_ones = torch.ones_like(target)\n",
    "#         labels = target\n",
    "#         losses = all_ones - torch.mul(output, labels)\n",
    "\n",
    "#         return torch.norm(self.relu(losses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_2d(target):\n",
    "    n = target.shape[0]\n",
    "    target_new = torch.zeros((n,2),dtype=torch.long).cuda()\n",
    "    for i in range(n):\n",
    "        target_new[i,target[i]] = 1\n",
    "    return target_new\n",
    "\n",
    "def train_linear_svm(cnn_model, svm_model, train_batches, test_batches, num_epochs):\n",
    "    # TODO: Write a training loop for the linear SVM\n",
    "    # Keep in mind that the CNN model is needed to compute features, but it should not be finetuned\n",
    "    \n",
    "    print(\"Training Linear SVM...\")\n",
    "    criterion = MyHingeLoss()\n",
    "    # criterion = nn.MultiLabelMarginLoss()\n",
    "    optimizer = optim.Adam(svm_model.parameters(), lr=0.0001)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            output = svm_model(cnn_model.get_repr(images)).squeeze()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            # labels = labels.contiguous().view(-1, 1).repeat((1,2))\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Training loss after epoch {}: {}\".format(epoch, total_loss/len(train_batches)))\n",
    "        test_linear_svm(cnn_model, svm_model, test_batches)\n",
    "    return\n",
    "\n",
    "\n",
    "def test_linear_svm(cnn_model, svm_model, test_batches):\n",
    "    criterion = MyHingeLoss()\n",
    "    # criterion = nn.MultiLabelMarginLoss()\n",
    "    # TODO: Write a testing function for the linear SVM\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        class_gold = [0.0] * NUM_CLASSES\n",
    "        class_pred = [0.0] * NUM_CLASSES\n",
    "        class_correct = [0.0] * NUM_CLASSES\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            output = svm_model(cnn_model.get_repr(images))\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, output = torch.max(output, axis=1)\n",
    "            visualize_grayscale_image(output.view(32, 32).cpu().numpy(), i)\n",
    "            output = output.squeeze().cpu().numpy().astype(int)\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze().cpu().numpy()\n",
    "            cur_class_pred = np.unique(output, return_counts=True)\n",
    "            for key, val in zip(cur_class_pred[0], cur_class_pred[1]):\n",
    "                class_pred[key] += val\n",
    "            cur_class_gold = np.unique(labels, return_counts=True)\n",
    "            for key, val in zip(cur_class_gold[0], cur_class_gold[1]):\n",
    "                class_gold[key] += val\n",
    "            cur_correct = (output == labels).tolist()\n",
    "            for j, val in enumerate(cur_correct):\n",
    "                if val:\n",
    "                    class_correct[labels[j]] += 1\n",
    "            correct += np.sum(cur_correct)\n",
    "            total += len(labels)\n",
    "        print(\"Testing loss after epoch: {}\".format(total_loss/len(test_batches)))\n",
    "        class_iou = [x/(y+z-x) for x, y, z in zip(class_correct, class_gold, class_pred)]\n",
    "        mean_iou = sum(class_iou) / len(class_correct)\n",
    "        print(\"LinearSVM Mean IOU: {}\".format(mean_iou))\n",
    "        print(\"LinearSVM Pixel Accuracy: {}\".format(correct / total))\n",
    "        print()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM...\n",
      "Training loss after epoch 0: 38.42778907775879\n",
      "Testing loss after epoch: 35.25559211881451\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n",
      "Training loss after epoch 1: 34.44132444190979\n",
      "Testing loss after epoch: 34.282492273667664\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n",
      "Training loss after epoch 2: 33.880603281497955\n",
      "Testing loss after epoch: 33.89866800332764\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n",
      "Testing loss after epoch: 33.7090067076683\n",
      "LinearSVM Mean IOU: 0.39865185546875\n",
      "LinearSVM Pixel Accuracy: 0.7973037109375\n",
      "\n",
      "Testing loss after epoch: 33.89866800332764\n",
      "LinearSVM Mean IOU: 0.40063937205188677\n",
      "LinearSVM Pixel Accuracy: 0.8012787441037735\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = LinearSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "# svm = LinearSVM(NUM_FEATURES, 1).cuda()\n",
    "\n",
    "train_linear_svm(cnn, svm, train_batches, test_batches, 3)\n",
    "test_linear_svm(cnn, svm, train_batches)\n",
    "test_linear_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_model(var_pot, edge_pot, target):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    assert var_pot.shape[0]==target.shape[0]\n",
    "    data = {}\n",
    "    n = 32\n",
    "    y_coef = []\n",
    "    x_coef = []\n",
    "    for i in range(edge_pot.shape[0]):\n",
    "        y_coef.append(int(var_pot.shape[0] * (edge_pot[i][0] - edge_pot[i][1])))\n",
    "        \n",
    "    for i in range(var_pot.shape[0]):\n",
    "        x_coef.append(int(var_pot.shape[0] * (var_pot[i][0] - var_pot[i][1]) + (2 * target[i] - 1)))\n",
    "    data['obj_coeffs'] = x_coef + y_coef\n",
    "    data['num_vars'] = var_pot.shape[0] + edge_pot.shape[0]\n",
    "    \n",
    "    \n",
    "    data['constraint_coeffs'] = []\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(0,n-1):\n",
    "        for j in range(0,n-1):\n",
    "            cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons1[i*n+j] = -1\n",
    "            cons1[idx+var_pot.shape[0]] = 1\n",
    "            cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons2[i*n+j+1] = -1\n",
    "            cons2[idx+var_pot.shape[0]] = 1\n",
    "            data['constraint_coeffs'].append(cons1)\n",
    "            data['constraint_coeffs'].append(cons2)\n",
    "            idx = idx + 1\n",
    "            \n",
    "            cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons1[i*n+j] = -1\n",
    "            cons1[idx+var_pot.shape[0]] = 1\n",
    "            cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "            cons2[i*n+j+n] = -1\n",
    "            cons2[idx+var_pot.shape[0]] = 1\n",
    "            data['constraint_coeffs'].append(cons1)\n",
    "            data['constraint_coeffs'].append(cons2)\n",
    "            idx = idx + 1\n",
    "\n",
    "        cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons1[i*n+n-1] = -1\n",
    "        cons1[idx+var_pot.shape[0]] = 1\n",
    "        cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons2[i*n+n+n-1] = -1\n",
    "        cons2[idx+var_pot.shape[0]] = 1\n",
    "        data['constraint_coeffs'].append(cons1)\n",
    "        data['constraint_coeffs'].append(cons2)\n",
    "        idx = idx + 1\n",
    "\n",
    "    for j in range(0,n-1):\n",
    "        cons1 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons1[(n-1)*n+j] = -1\n",
    "        cons1[idx+var_pot.shape[0]] = 1\n",
    "        cons2 = [0] * (var_pot.shape[0] + edge_pot.shape[0])\n",
    "        cons2[(n-1)*n+j+1] = -1\n",
    "        cons2[idx+var_pot.shape[0]] = 1\n",
    "        data['constraint_coeffs'].append(cons1)\n",
    "        data['constraint_coeffs'].append(cons2)\n",
    "        idx = idx + 1\n",
    "\n",
    "\n",
    "    assert idx == 2*(n-1)*n\n",
    "    \n",
    "    data['bounds'] = [0] * 2 * edge_pot.shape[0]\n",
    "    \n",
    "    assert len(data['bounds'])==len(data['constraint_coeffs'])\n",
    "    data['num_constraints'] = len(data['bounds'])\n",
    "    return data\n",
    "\n",
    "\n",
    "def MAP_infer(data):\n",
    "    \n",
    "    solver = pywraplp.Solver('ILP', pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "    infinity = solver.infinity()\n",
    "    x = {}\n",
    "    for j in range(data['num_vars']):\n",
    "        x[j] = solver.IntVar(0, 1, 'x[%i]' % j)\n",
    "    # print('Number of variables =', solver.NumVariables())\n",
    "\n",
    "    for i in range(data['num_constraints']):\n",
    "        constraint = solver.RowConstraint(0, data['bounds'][i], '')\n",
    "    for j in range(data['num_vars']):\n",
    "        constraint.SetCoefficient(x[j], data['constraint_coeffs'][i][j])\n",
    "    # print('Number of constraints =', solver.NumConstraints())\n",
    "    \n",
    "    # In Python, you can also set the constraints as follows.\n",
    "    # for i in range(data['num_constraints']):\n",
    "    #  constraint_expr = \\\n",
    "    # [data['constraint_coeffs'][i][j] * x[j] for j in range(data['num_vars'])]\n",
    "    #  solver.Add(sum(constraint_expr) <= data['bounds'][i])\n",
    "\n",
    "    objective = solver.Objective()\n",
    "    for j in range(data['num_vars']):\n",
    "        objective.SetCoefficient(x[j], data['obj_coeffs'][j])\n",
    "    objective.SetMaximization()\n",
    "    # In Python, you can also set the objective as follows.\n",
    "    # obj_expr = [data['obj_coeffs'][j] * x[j] for j in range(data['num_vars'])]\n",
    "    # solver.Maximize(solver.Sum(obj_expr))\n",
    "\n",
    "    status = solver.Solve()\n",
    "\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        result = []\n",
    "        # print('Objective value =', solver.Objective().Value())\n",
    "        for j in range(data['num_vars']):\n",
    "            result.append(x[j].solution_value())\n",
    "            # print(x[j].name(), ' = ', x[j].solution_value())\n",
    "        #print()\n",
    "        #print('Problem solved in %f milliseconds' % solver.wall_time())\n",
    "        #print('Problem solved in %d iterations' % solver.iterations())\n",
    "        #print('Problem solved in %d branch-and-bound nodes' % solver.nodes())\n",
    "        return result\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.')\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def make_y(x):\n",
    "        n = x.size(1)\n",
    "        dim = x.size(-1)\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        y = torch.zeros((2*(n-1)*n ,2*dim))\n",
    "        y_dict = dict()\n",
    "        \n",
    "        idx = 0\n",
    "        for i in range(0,n-1):\n",
    "            for j in range(0,n-1):\n",
    "                y_dict[(idx,(i*n+j,i*n+j+1))] = torch.cat([x[i*n+j],x[i*n+j+1]])\n",
    "                idx = idx + 1\n",
    "                y_dict[(idx,(i*n+j,i*n+j+n))] = torch.cat([x[i*n+j],x[i*n+j+n]])\n",
    "                idx = idx + 1\n",
    "        \n",
    "            y_dict[(idx,(i*n+n-1,i*n+n+n-1))] = torch.cat([x[i*n+n-1],x[i*n+n+n-1]])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        for j in range(0,n-1):\n",
    "            y_dict[(idx,((n-1)*n+j,(n-1)*n+j+1))] = torch.cat([x[(n-1)*n+j],x[(n-1)*n+j+1]])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        assert idx == 2*(n-1)*n\n",
    "        for key in y_dict.keys():\n",
    "            y[key[0],:] = y_dict[key]\n",
    "        \n",
    "        return y, y_dict\n",
    "    \n",
    "    \n",
    "def make_y_label(x):\n",
    "        n = x.size(1)\n",
    "        dim = x.size(-1)\n",
    "        assert dim==2\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        x = x[:,0]\n",
    "        y = torch.zeros((2*(n-1)*n ,dim))\n",
    "        y_dict = dict()\n",
    "        \n",
    "        idx = 0\n",
    "        for i in range(0,n-1):\n",
    "            for j in range(0,n-1):\n",
    "                y_dict[(idx,(i*n+j,i*n+j+1))] = int(x[i*n+j]==x[i*n+j+1])\n",
    "                idx = idx + 1\n",
    "                y_dict[(idx,(i*n+j,i*n+j+n))] = int(x[i*n+j]==x[i*n+j+n])\n",
    "                idx = idx + 1\n",
    "        \n",
    "            y_dict[(idx,(i*n+n-1,i*n+n+n-1))] = int(x[i*n+n-1]==x[i*n+n+n-1])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        for j in range(0,n-1):\n",
    "            y_dict[(idx,((n-1)*n+j,(n-1)*n+j+1))] = int(x[(n-1)*n+j]==x[(n-1)*n+j+1])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        assert idx == 2*(n-1)*n\n",
    "        for key in y_dict.keys():\n",
    "            y[key[0],y_dict[key]] = 1\n",
    "        \n",
    "        return y, y_dict\n",
    "\n",
    "class StructSVM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feat, n_classes):\n",
    "        super(StructSVM, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.n_classes = n_classes\n",
    "        self.w_var = nn.Parameter(torch.ones(n_classes, n_feat), requires_grad=True)\n",
    "        self.w_edge = nn.Parameter(torch.ones(n_classes, 2*n_feat), requires_grad=True)\n",
    "        # TODO: Define weights for structured SVM\n",
    "       \n",
    "\n",
    "    def forward(self, x, target):\n",
    "        # TODO: Define forward function for structured SVM\n",
    "        y, _ = make_y(x)\n",
    "        y = y.cuda()\n",
    "        x = x.view(-1, x.size(-1))\n",
    "        var_pot = x.matmul(self.w_var.t())\n",
    "        edge_pot = y.matmul(self.w_edge.t())\n",
    "        data = create_data_model(torch.clone(var_pot).cpu().detach().numpy().squeeze(), \n",
    "                                 torch.clone(edge_pot).cpu().detach().numpy().squeeze(), \n",
    "                                 torch.clone(target).cpu().detach().numpy().squeeze())\n",
    "        result = MAP_infer(data)\n",
    "        x_out = torch.zeros((var_pot.size(0),2))\n",
    "        y_out = torch.zeros((edge_pot.size(0),2))\n",
    "        for i in range(var_pot.size(0)):\n",
    "            x_out[i,0] = result[i]\n",
    "            x_out[i,1] = 1 - result[i]\n",
    "        for i in range(edge_pot.size(0)):\n",
    "            y_out[i, 0] = result[i + var_pot.size(0)]\n",
    "            y_out[i, 1] = 1 - result[i + var_pot.size(0)]\n",
    "        return x_out.cuda(), y_out.cuda(), var_pot.cuda().squeeze(), edge_pot.cuda().squeeze()\n",
    "    \n",
    "\n",
    "\n",
    "class MyStructedHingeLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyStructedHingeLoss, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "    \n",
    "    def S_func(self, x, y, var_pot, edge_pot):\n",
    "        \n",
    "        sum_x_out = torch.sum(var_pot*x)\n",
    "        sum_y_out = torch.sum(edge_pot*y)\n",
    "        \n",
    "        return sum_x_out + sum_y_out\n",
    "    \n",
    "    def x_loss(self, x, target_x):\n",
    "        assert x.shape[0]==target_x.shape[0]\n",
    "        x0 = x[:,0]\n",
    "        xt0 = target_x[:,0]\n",
    "        return 1 - torch.sum(x0==xt0)/x.shape[0]\n",
    "    \n",
    "    def forward(self, x_out, y_out, var_pot, edge_pot, target):\n",
    "        S_output = self.S_func(x_out, y_out, var_pot, edge_pot)\n",
    "        target_x = torch.zeros((target.size(0),2))\n",
    "        for i in range(target.size(0)):\n",
    "            target_x[i, target[i]] = 1\n",
    "        target_y, _ = make_y_label(target_x.reshape(1,32,32,-1))\n",
    "        target_x = target_x.cuda()\n",
    "        target_y = target_y.cuda()\n",
    "        S_target = self.S_func(target_x, target_y, var_pot, edge_pot)\n",
    "        loss_x = self.x_loss(x_out, target_x)\n",
    "        losses = S_output + loss_x - S_target\n",
    "        return torch.sum(self.relu(losses))\n",
    "\n",
    "def train_struct_svm(cnn_model, svm_model, train_batches, test_batches, num_epochs):\n",
    "    # TODO: Write a training loop for the structured SVM\n",
    "    # Keep in mind that the CNN model is needed to compute features, but it should not be finetuned\n",
    "    print(\"Training Struct SVM...\")\n",
    "    criterion = MyStructedHingeLoss()\n",
    "    optimizer = optim.Adam(svm_model.parameters(), lr=0.0001) \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            x_out, y_out, var_pot, edge_pot = svm_model(cnn_model.get_repr(images), labels)\n",
    "            loss = criterion(x_out, y_out, var_pot, edge_pot, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Training loss after epoch {}: {}\".format(epoch, total_loss/len(train_batches)))\n",
    "        test_struct_svm(cnn_model, svm_model, test_batches)\n",
    "    return\n",
    "\n",
    "\n",
    "def test_struct_svm(cnn_model, svm_model, test_batches):\n",
    "    # TODO: Write a testing function for the structured SVM\n",
    "    criterion = MyStructedHingeLoss()\n",
    "    with torch.no_grad():\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        class_gold = [0.0] * NUM_CLASSES\n",
    "        class_pred = [0.0] * NUM_CLASSES\n",
    "        class_correct = [0.0] * NUM_CLASSES\n",
    "        total_loss = 0.0\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            images, labels = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze()\n",
    "            x_out, y_out, var_pot, edge_pot = svm_model(cnn_model.get_repr(images), labels)\n",
    "            loss = criterion(x_out, y_out, var_pot, edge_pot, labels)\n",
    "            total_loss += loss.item()        \n",
    "            _, output = torch.max(x_out, axis=1)\n",
    "            visualize_grayscale_image(output.view(32, 32).cpu().numpy(), i)\n",
    "            output = output.squeeze().cpu().numpy().astype(int)\n",
    "            labels = labels.contiguous().view(-1, 1).squeeze().cpu().numpy()\n",
    "            cur_class_pred = np.unique(output, return_counts=True)\n",
    "            for key, val in zip(cur_class_pred[0], cur_class_pred[1]):\n",
    "                class_pred[key] += val\n",
    "            cur_class_gold = np.unique(labels, return_counts=True)\n",
    "            for key, val in zip(cur_class_gold[0], cur_class_gold[1]):\n",
    "                class_gold[key] += val\n",
    "            cur_correct = (output == labels).tolist()\n",
    "            for j, val in enumerate(cur_correct):\n",
    "                if val:\n",
    "                    class_correct[labels[j]] += 1\n",
    "            correct += np.sum(cur_correct)\n",
    "            total += len(labels)\n",
    "        \n",
    "        print(\"Testing loss after epoch: {}\".format(total_loss/len(test_batches)))\n",
    "        class_iou = [x/(y+z-x) for x, y, z in zip(class_correct, class_gold, class_pred)]\n",
    "        mean_iou = sum(class_iou) / len(class_correct)\n",
    "        print(\"StructSVM Mean IOU: {}\".format(mean_iou))\n",
    "        print(\"StructSVM Pixel Accuracy: {}\".format(correct / total))\n",
    "        print()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Struct SVM...\n",
      "Training loss after epoch 0: 1.59883642578125\n",
      "Testing loss after epoch: 1.195144993567753\n",
      "StructSVM Mean IOU: 0.25020651965686713\n",
      "StructSVM Pixel Accuracy: 0.4993199238850772\n",
      "\n",
      "Training loss after epoch 1: 1.95348828125\n",
      "Testing loss after epoch: 2.7242366731882504\n",
      "StructSVM Mean IOU: 0.3996097514378091\n",
      "StructSVM Pixel Accuracy: 0.6681865083619211\n",
      "\n",
      "Training loss after epoch 2: 1.6813544921875\n",
      "Testing loss after epoch: 8.386810878537736\n",
      "StructSVM Mean IOU: 0.30548136173024787\n",
      "StructSVM Pixel Accuracy: 0.6107619532590052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = StructSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "\n",
    "train_struct_svm(cnn, svm, train_batches, test_batches, 5)\n",
    "test_struct_svm(cnn, svm, train_batches)\n",
    "test_struct_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Struct SVM...\n",
      "Training loss after epoch 0: 1.8219443359375\n",
      "Testing loss after epoch: 0.7812089609240995\n",
      "StructSVM Mean IOU: 0.2886221194510217\n",
      "StructSVM Pixel Accuracy: 0.5771434123070326\n",
      "\n",
      "Training loss after epoch 1: 1.7334931640625\n",
      "Testing loss after epoch: 1.6731078473413379\n",
      "StructSVM Mean IOU: 0.2808926425588986\n",
      "StructSVM Pixel Accuracy: 0.5616155660377359\n",
      "\n",
      "Training loss after epoch 2: 1.5113525390625\n",
      "Testing loss after epoch: 1.5924660631968268\n",
      "StructSVM Mean IOU: 0.3811725868805567\n",
      "StructSVM Pixel Accuracy: 0.7623385237993139\n",
      "\n",
      "Training loss after epoch 3: 1.59384716796875\n",
      "Testing loss after epoch: 1.5415809592088336\n",
      "StructSVM Mean IOU: 0.32008887891295024\n",
      "StructSVM Pixel Accuracy: 0.6401777578259005\n",
      "\n",
      "Training loss after epoch 4: 1.8127265625\n",
      "Testing loss after epoch: 1.8644923215051459\n",
      "StructSVM Mean IOU: 0.39419012348011595\n",
      "StructSVM Pixel Accuracy: 0.7880557863421955\n",
      "\n",
      "Testing loss after epoch: 1.8161240234375\n",
      "StructSVM Mean IOU: 0.39179452303475293\n",
      "StructSVM Pixel Accuracy: 0.7833056640625\n",
      "\n",
      "Testing loss after epoch: 1.8644923215051459\n",
      "StructSVM Mean IOU: 0.39419012348011595\n",
      "StructSVM Pixel Accuracy: 0.7880557863421955\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = StructSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "\n",
    "train_struct_svm(cnn, svm, train_batches, test_batches, 5)\n",
    "test_struct_svm(cnn, svm, train_batches)\n",
    "test_struct_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Struct SVM...\n",
      "Training loss after epoch 0: 1.80068701171875\n",
      "Testing loss after epoch: 1.2287844728237565\n",
      "StructSVM Mean IOU: 0.37548324870972616\n",
      "StructSVM Pixel Accuracy: 0.7508593079974271\n",
      "\n",
      "Training loss after epoch 1: 1.55786865234375\n",
      "Testing loss after epoch: 1.2760581381325042\n",
      "StructSVM Mean IOU: 0.22243471134694276\n",
      "StructSVM Pixel Accuracy: 0.44263407214837047\n",
      "\n",
      "Training loss after epoch 2: 1.7956650390625\n",
      "Testing loss after epoch: 1.3600324627465694\n",
      "StructSVM Mean IOU: 0.36345467146804006\n",
      "StructSVM Pixel Accuracy: 0.7265976763507719\n",
      "\n",
      "Training loss after epoch 3: 1.8317763671875\n",
      "Testing loss after epoch: 1.7321019377144082\n",
      "StructSVM Mean IOU: 0.3088849972244766\n",
      "StructSVM Pixel Accuracy: 0.6175643894725558\n",
      "\n",
      "Training loss after epoch 4: 1.79480078125\n",
      "Testing loss after epoch: 0.8316577106560892\n",
      "StructSVM Mean IOU: 0.33391710300817223\n",
      "StructSVM Pixel Accuracy: 0.6678297196612349\n",
      "\n",
      "Testing loss after epoch: 0.8120087890625\n",
      "StructSVM Mean IOU: 0.3275340674594989\n",
      "StructSVM Pixel Accuracy: 0.6550556640625\n",
      "\n",
      "Testing loss after epoch: 0.8316577106560892\n",
      "StructSVM Mean IOU: 0.33391710300817223\n",
      "StructSVM Pixel Accuracy: 0.6678297196612349\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = StructSVM(NUM_FEATURES, NUM_CLASSES).cuda()\n",
    "\n",
    "train_struct_svm(cnn, svm, train_batches, test_batches, 5)\n",
    "test_struct_svm(cnn, svm, train_batches)\n",
    "test_struct_svm(cnn, svm, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
